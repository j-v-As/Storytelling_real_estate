{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50GgQk6QuPLh",
        "outputId": "9462dd32-24ad-43f5-baad-c598867f9ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Unnamed: 0',\n",
              " 'ada_embedding_eng',\n",
              " 'numerical_price',\n",
              " 'num_bedrooms',\n",
              " 'num_rooms',\n",
              " 'building_type_Bestaande bouw',\n",
              " 'building_type_Nieuwbouw',\n",
              " 'building_type_na',\n",
              " 'tag_k.k.',\n",
              " 'tag_v.o.n.',\n",
              " 'house_category_Appartement',\n",
              " 'house_category_Bungalow',\n",
              " 'house_category_Eengezinswoning',\n",
              " 'house_category_Grachtenpand',\n",
              " 'house_category_Herenhuis',\n",
              " 'house_category_Landhuis',\n",
              " 'house_category_Other',\n",
              " 'house_category_Unknown',\n",
              " 'house_category_Villa',\n",
              " 'house_category_Woonboerderij',\n",
              " 'house_category_Woonboot',\n",
              " 'energy_label_encoded',\n",
              " 'size_scaled',\n",
              " 'longitude_scaled',\n",
              " 'latitude_scaled']"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# This will prompt for authorization to access your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Update the file path to the location where you uploaded your CSV in Google Drive\n",
        "file_path = '/content/drive/My Drive/Thesis/df-englisch_cat.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.columns.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(df.columns[0], axis=1)"
      ],
      "metadata": {
        "id": "0_Ln_piu3Pxq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "y = df['numerical_price']\n",
        "\n",
        "# Dropping the 'ada_embedding_eng' column from df\n",
        "z = df.drop([\"ada_embedding_eng\", \"numerical_price\"], axis=1)\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(z, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "8aWQLg7humAc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test, best_params):\n",
        "    \"\"\"\n",
        "    Trains the Random Forest model with the given parameters and evaluates it on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    x_train (list/array): Training features\n",
        "    y_train (list/array): Training target variable\n",
        "    x_test (list/array): Test features\n",
        "    y_test (list/array): Test target variable\n",
        "    best_params (dict): Dictionary of best hyperparameters\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing R2, MSE, and RMSE metrics\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize RandomForestRegressor with best parameters\n",
        "    clf_rf_best = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Initialize and fit StandardScaler on y_train\n",
        "    scaler = StandardScaler()\n",
        "    y_train_scaled = scaler.fit_transform(np.array(y_train).reshape(-1, 1))\n",
        "\n",
        "    # Train the model on the entire training dataset\n",
        "    clf_rf_best.fit(x_train, y_train_scaled.ravel())\n",
        "\n",
        "    # Predict on the test data and inverse transform the predictions\n",
        "    y_pred_scaled = clf_rf_best.predict(x_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "      # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R-squared Score\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    # Explained Variance Score\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    return {\"R2\": r2_score_value, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape,\"explained\":explained_variance}\n",
        "\n",
        "\n",
        "best_params = {'max_depth': 22, 'n_estimators': 300, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 8, 'bootstrap': False}\n",
        "performance_metrics = train_and_evaluate(x_train, y_train, x_test, y_test, best_params)\n",
        "print(\"Final Model Performance on Test Set:\", performance_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjkFbEK-u96Q",
        "outputId": "667f0b88-a151-4aa4-ac4d-7949c00c2e9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model Performance on Test Set: {'R2': 0.7623871847600269, 'MSE': 38234334087.846054, 'RMSE': 195536.01736725142, 'MAE': 91330.68687623629, 'MAPE': 16.00861377761797, 'explained': 0.7623964660475206}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_model(x_train, y_train, x_test, y_test, params):\n",
        "    \"\"\"\n",
        "    Train and evaluate a neural network model.\n",
        "\n",
        "    Parameters:\n",
        "    - x_train: Training features\n",
        "    - y_train: Training target values\n",
        "    - x_test: Test features\n",
        "    - y_test: Test target values\n",
        "    - params: Dictionary containing the optimal parameters\n",
        "\n",
        "    Returns:\n",
        "    - R2 score, MSE, and RMSE on the test set.\n",
        "    \"\"\"\n",
        "    x_train = x_train.to_numpy()\n",
        "    x_test = x_test.to_numpy()\n",
        "    y_train = y_train.to_numpy()\n",
        "    y_test = y_test.to_numpy()\n",
        "\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    y_train = y_train.astype('float32')\n",
        "    y_test = y_test.astype('float32')\n",
        "\n",
        "\n",
        "    y_train = np.ravel(y_train)\n",
        "    y_test = np.ravel(y_test)\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    if params['regularization'] == 'l1':\n",
        "        reg = l1(params['l1_reg'])\n",
        "    elif params['regularization'] == 'l2':\n",
        "        reg = l2(0)\n",
        "    elif params['regularization'] == 'l1_l2':\n",
        "        reg = l1_l2(l1=params['l1_reg'], l2=0)\n",
        "    else:\n",
        "        reg = None\n",
        "\n",
        "    model.add(Dense(params['neurons_layer_1'], activation='relu', input_shape=(x_train.shape[1],), kernel_regularizer=reg))\n",
        "    model.add(Dense(params['neurons_layer_2'], activation='relu', kernel_regularizer=reg))\n",
        "    model.add(Dense(params['neurons_layer_3'], activation='relu', kernel_regularizer=reg))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Scaling y_train\n",
        "    scaler = StandardScaler()\n",
        "    y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(x_train, y_train_scaled, epochs=params['epochs'], batch_size=params['batch_size'], verbose=1)\n",
        "\n",
        "    # Predict and evaluate on the test set\n",
        "    y_pred_scaled = model.predict(x_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "      # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R-squared Score\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    # Explained Variance Score\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    return {\"R2\": r2_score_value, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape,\"explained\":explained_variance}\n",
        "\n",
        "\n",
        "optimal_params = {'learning_rate': 0.0001481458629411212, 'neurons_layer_1': 416, 'neurons_layer_2': 208, 'neurons_layer_3': 80, 'batch_size': 128, 'epochs': 72, 'regularization': 'l1', 'l1_reg': 9.650241971828681e-05}\n",
        "\n",
        "performance_metrics = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
        "print(\"Final Model Performance on Test Set:\", performance_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAo4cJI0wByH",
        "outputId": "dd3315ee-180a-4804-887c-0389053917cf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/72\n",
            "451/451 [==============================] - 2s 3ms/step - loss: 0.9368\n",
            "Epoch 2/72\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.7572\n",
            "Epoch 3/72\n",
            "451/451 [==============================] - 2s 3ms/step - loss: 0.7036\n",
            "Epoch 4/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.6621\n",
            "Epoch 5/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.6364\n",
            "Epoch 6/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.6150\n",
            "Epoch 7/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5951\n",
            "Epoch 8/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5767\n",
            "Epoch 9/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5656\n",
            "Epoch 10/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.5440\n",
            "Epoch 11/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.5382\n",
            "Epoch 12/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5275\n",
            "Epoch 13/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5148\n",
            "Epoch 14/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5057\n",
            "Epoch 15/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.5031\n",
            "Epoch 16/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4928\n",
            "Epoch 17/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4833\n",
            "Epoch 18/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4718\n",
            "Epoch 19/72\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4698\n",
            "Epoch 20/72\n",
            "451/451 [==============================] - 2s 3ms/step - loss: 0.4592\n",
            "Epoch 21/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4553\n",
            "Epoch 22/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4478\n",
            "Epoch 23/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4458\n",
            "Epoch 24/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4366\n",
            "Epoch 25/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4328\n",
            "Epoch 26/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4241\n",
            "Epoch 27/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.4162\n",
            "Epoch 28/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.4090\n",
            "Epoch 29/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4099\n",
            "Epoch 30/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.4072\n",
            "Epoch 31/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3983\n",
            "Epoch 32/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3933\n",
            "Epoch 33/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3926\n",
            "Epoch 34/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3846\n",
            "Epoch 35/72\n",
            "451/451 [==============================] - 2s 3ms/step - loss: 0.3925\n",
            "Epoch 36/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3984\n",
            "Epoch 37/72\n",
            "451/451 [==============================] - 2s 3ms/step - loss: 0.3742\n",
            "Epoch 38/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3735\n",
            "Epoch 39/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3674\n",
            "Epoch 40/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3666\n",
            "Epoch 41/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3657\n",
            "Epoch 42/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3657\n",
            "Epoch 43/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3560\n",
            "Epoch 44/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3557\n",
            "Epoch 45/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3520\n",
            "Epoch 46/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3486\n",
            "Epoch 47/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3461\n",
            "Epoch 48/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3429\n",
            "Epoch 49/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3385\n",
            "Epoch 50/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3393\n",
            "Epoch 51/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3335\n",
            "Epoch 52/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3341\n",
            "Epoch 53/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3280\n",
            "Epoch 54/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3322\n",
            "Epoch 55/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3293\n",
            "Epoch 56/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3254\n",
            "Epoch 57/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3256\n",
            "Epoch 58/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3199\n",
            "Epoch 59/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3184\n",
            "Epoch 60/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3170\n",
            "Epoch 61/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3154\n",
            "Epoch 62/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3169\n",
            "Epoch 63/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3130\n",
            "Epoch 64/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3112\n",
            "Epoch 65/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3106\n",
            "Epoch 66/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3056\n",
            "Epoch 67/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3066\n",
            "Epoch 68/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3074\n",
            "Epoch 69/72\n",
            "451/451 [==============================] - 2s 3ms/step - loss: 0.3022\n",
            "Epoch 70/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.3030\n",
            "Epoch 71/72\n",
            "451/451 [==============================] - 2s 4ms/step - loss: 0.2993\n",
            "Epoch 72/72\n",
            "451/451 [==============================] - 1s 3ms/step - loss: 0.3012\n",
            "451/451 [==============================] - 1s 1ms/step\n",
            "Final Model Performance on Test Set: {'R2': 0.7075435960668552, 'MSE': 47059227000.0, 'RMSE': 216931.39, 'MAE': 110939.84, 'MAPE': 18.218155205249786, 'explained': 0.728867769241333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def run_svr_and_evaluate(x_train,x_test, y_train,y_test ):\n",
        "    # Split data into training and testing sets\n",
        "\n",
        "\n",
        "    # Initialize SVR with your predefined parameters\n",
        "    clf_svr_opt =  LinearSVR(**linear_svr_params, random_state=0)\n",
        "\n",
        "    # StandardScaler for y\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Scaling\n",
        "    y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "    # Fitting the model\n",
        "    clf_svr_opt.fit(x_train, y_train_scaled)\n",
        "\n",
        "    # Predicting and inverse transformation for the test set\n",
        "    y_pred_scaled = clf_svr_opt.predict(x_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "      # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R-squared Score\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    # Explained Variance Score\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    return {\"R2\": r2_score_value, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape,\"explained\":explained_variance}\n",
        "\n",
        "\n",
        "linear_svr_params = {'C': 0.012413439869308911, 'epsilon': 0.0029686327476415772, 'tol': 9.433742678639591e-05, 'loss': 'squared_epsilon_insensitive', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 5.864212196204296, 'max_iter': 5428}\n",
        "\n",
        "performance_metrics = run_svr_and_evaluate(x_train=x_train,x_test=x_test, y_train=y_train,y_test=y_test)\n",
        "print(\"Final Model Performance on Test Set:\", performance_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zp-KoYwlw7f3",
        "outputId": "5bf9e671-82a2-446d-b446-977e5a57f667"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model Performance on Test Set: {'R2': 0.5645547838746261, 'MSE': 70067592328.62732, 'RMSE': 264702.83777970215, 'MAE': 140921.2718668702, 'MAPE': 26.338464998406103, 'explained': 0.5645726272085992}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aWGFRbF9wx0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}