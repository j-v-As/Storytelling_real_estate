{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numerical_price',\n",
       " 'num_bedrooms',\n",
       " 'num_rooms',\n",
       " 'f_string_embedding',\n",
       " 'building_type_Bestaande bouw',\n",
       " 'building_type_Nieuwbouw',\n",
       " 'building_type_na',\n",
       " 'tag_k.k.',\n",
       " 'tag_v.o.n.',\n",
       " 'house_category_Appartement',\n",
       " 'house_category_Bungalow',\n",
       " 'house_category_Eengezinswoning',\n",
       " 'house_category_Grachtenpand',\n",
       " 'house_category_Herenhuis',\n",
       " 'house_category_Landhuis',\n",
       " 'house_category_Other',\n",
       " 'house_category_Unknown',\n",
       " 'house_category_Villa',\n",
       " 'house_category_Woonboerderij',\n",
       " 'house_category_Woonboot',\n",
       " 'energy_label_encoded',\n",
       " 'size_scaled',\n",
       " 'longitude_scaled',\n",
       " 'latitude_scaled']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### final model NN MIXED\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\JellevanAs\\\\Documents\\\\Studie\\\\Thesis\\\\df-formatted_cat.csv\")\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.drop('size_int',axis= 1)\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df[\"f_string_embedding\"] = df[\"f_string_embedding\"].apply(literal_eval).apply(np.array)\n",
    "\n",
    "\n",
    "x = df[\"f_string_embedding\"]\n",
    "y = df['numerical_price']\n",
    "\n",
    "# Dropping the 'ada_embedding_eng' column from df\n",
    "z = df.drop([\"f_string_embedding\", \"numerical_price\"], axis=1)\n",
    "\n",
    "\n",
    "# Deleting original dataframe for memory purpose\n",
    "del df\n",
    "\n",
    "# Explode the embedding arrays into separate columns\n",
    "x = x.apply(pd.Series)\n",
    "\n",
    "# Concatenating the exploded embeddings with the rest of the data\n",
    "concatenated_df = pd.concat([x, z], axis=1).reset_index(drop=True)\n",
    "concatenated_df.columns = concatenated_df.columns.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(concatenated_df, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "import numpy as np\n",
    "\n",
    "def train_and_evaluate_model(x_train, y_train, x_test, y_test, params):\n",
    "    \"\"\"\n",
    "    Train and evaluate a neural network model.\n",
    "\n",
    "    Parameters:\n",
    "    - x_train: Training features\n",
    "    - y_train: Training target values\n",
    "    - x_test: Test features\n",
    "    - y_test: Test target values\n",
    "    - params: Dictionary containing the optimal parameters\n",
    "\n",
    "    Returns:\n",
    "    - R2 score, MSE, and RMSE on the test set.\n",
    "    \"\"\"\n",
    "    x_train = x_train.to_numpy()\n",
    "    x_test = x_test.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "\n",
    "    \n",
    "    y_train = np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "\n",
    "\n",
    " \n",
    "    model = Sequential()\n",
    "    if params['regularization'] == 'l1':\n",
    "        reg = l1(params['l1_reg'])\n",
    "    elif params['regularization'] == 'l2':\n",
    "        reg = l2(0)  \n",
    "    elif params['regularization'] == 'l1_l2':\n",
    "        reg = l1_l2(l1=params['l1_reg'], l2=0)  \n",
    "    else:\n",
    "        reg = None\n",
    "\n",
    "    model.add(Dense(params['neurons_layer_1'], activation='relu', input_shape=(x_train.shape[1],), kernel_regularizer=reg))\n",
    "    model.add(Dense(params['neurons_layer_2'], activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dense(params['neurons_layer_3'], activation='relu', kernel_regularizer=reg))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "    # Scaling y_train\n",
    "    scaler = StandardScaler()\n",
    "    y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(x_train, y_train_scaled, epochs=params['epochs'], batch_size=params['batch_size'], verbose=1)\n",
    "\n",
    "    # Predict and evaluate on the test set\n",
    "    y_pred_scaled = model.predict(x_test)\n",
    "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "     # Mean Squared Error\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    # Root Mean Squared Error\n",
    "    rmse = np.sqrt(mse)\n",
    "    # R-squared Score\n",
    "    r2_score_value = r2_score(y_test, y_pred)\n",
    "    # Mean Absolute Error\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    # Mean Absolute Percentage Error\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "    # Explained Variance Score\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "    return r2_score_value, mse, rmse, mae, mape, explained_variance\n",
    "\n",
    "\n",
    "optimal_params = {'learning_rate': 0.0008940829673560239, 'neurons_layer_1': 272, 'neurons_layer_2': 256, 'neurons_layer_3': 192, 'batch_size': 128, 'epochs': 92, 'regularization': 'none'}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "451/451 [==============================] - 5s 8ms/step - loss: 0.3602\n",
      "Epoch 2/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2853\n",
      "Epoch 3/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2405\n",
      "Epoch 4/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2371\n",
      "Epoch 5/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.2010\n",
      "Epoch 6/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.2015\n",
      "Epoch 7/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.1761\n",
      "Epoch 8/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1627\n",
      "Epoch 9/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1708\n",
      "Epoch 10/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1490\n",
      "Epoch 11/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1437\n",
      "Epoch 12/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1251\n",
      "Epoch 13/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.1514\n",
      "Epoch 14/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1263\n",
      "Epoch 15/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1156\n",
      "Epoch 16/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1382\n",
      "Epoch 17/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1112\n",
      "Epoch 18/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1119\n",
      "Epoch 19/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0999\n",
      "Epoch 20/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0958\n",
      "Epoch 21/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0897\n",
      "Epoch 22/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0997\n",
      "Epoch 23/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0931\n",
      "Epoch 24/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0844\n",
      "Epoch 25/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0921\n",
      "Epoch 26/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0932\n",
      "Epoch 27/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0994\n",
      "Epoch 28/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0797\n",
      "Epoch 29/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0749\n",
      "Epoch 30/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0739\n",
      "Epoch 31/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0745\n",
      "Epoch 32/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0737\n",
      "Epoch 33/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0853\n",
      "Epoch 34/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0687\n",
      "Epoch 35/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0638\n",
      "Epoch 36/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0658\n",
      "Epoch 37/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0634\n",
      "Epoch 38/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0632\n",
      "Epoch 39/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0701\n",
      "Epoch 40/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0632\n",
      "Epoch 41/92\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0604\n",
      "Epoch 42/92\n",
      "451/451 [==============================] - 5s 12ms/step - loss: 0.0589\n",
      "Epoch 43/92\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0637\n",
      "Epoch 44/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0524\n",
      "Epoch 45/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0544\n",
      "Epoch 46/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0589\n",
      "Epoch 47/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0577\n",
      "Epoch 48/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0511\n",
      "Epoch 49/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0551\n",
      "Epoch 50/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0516\n",
      "Epoch 51/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0456\n",
      "Epoch 52/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0444\n",
      "Epoch 53/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0453\n",
      "Epoch 54/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0501\n",
      "Epoch 55/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0457\n",
      "Epoch 56/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0536\n",
      "Epoch 57/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0460\n",
      "Epoch 58/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0798\n",
      "Epoch 59/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0437\n",
      "Epoch 60/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0443\n",
      "Epoch 61/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0461\n",
      "Epoch 62/92\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0390\n",
      "Epoch 63/92\n",
      "451/451 [==============================] - 6s 12ms/step - loss: 0.0439\n",
      "Epoch 64/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0433\n",
      "Epoch 65/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0422\n",
      "Epoch 66/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0396\n",
      "Epoch 67/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0562\n",
      "Epoch 68/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0360\n",
      "Epoch 69/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0375\n",
      "Epoch 70/92\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0350\n",
      "Epoch 71/92\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.0513\n",
      "Epoch 72/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0335\n",
      "Epoch 73/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0308\n",
      "Epoch 74/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0339\n",
      "Epoch 75/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0332\n",
      "Epoch 76/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0422\n",
      "Epoch 77/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0406\n",
      "Epoch 78/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0313\n",
      "Epoch 79/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0379\n",
      "Epoch 80/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0367\n",
      "Epoch 81/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0329\n",
      "Epoch 82/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0295\n",
      "Epoch 83/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0303\n",
      "Epoch 84/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0270\n",
      "Epoch 85/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0282\n",
      "Epoch 86/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0352\n",
      "Epoch 87/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0343\n",
      "Epoch 88/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0381\n",
      "Epoch 89/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0330\n",
      "Epoch 90/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0417\n",
      "Epoch 91/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0300\n",
      "Epoch 92/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0248\n",
      "451/451 [==============================] - 1s 3ms/step\n",
      "R2 Score on Test Data: 0.836419529738797\n",
      "Mean Squared Error: 26321770000.0\n",
      "Root Mean Squared Error: 162239.86\n",
      "Mean Absolute Error: 75716.8\n",
      "Mean Absolute percentage Error: 13.023446500301361\n",
      "explained variance 0.8372210264205933\n"
     ]
    }
   ],
   "source": [
    "\n",
    "r2_score_value, mse, rmse, mae, mape, explained_variance = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
    "print(\"R2 Score on Test Data:\", r2_score_value)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute percentage Error:\", mape)\n",
    "print(\"explained variance\", explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\JellevanAs\\\\Documents\\\\Studie\\\\Thesis\\\\df-englisch_cat.csv\")\n",
    "\n",
    "df.columns.tolist()\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df[\"ada_embedding_eng\"] = df[\"ada_embedding_eng\"].apply(literal_eval).apply(np.array)\n",
    "\n",
    "# Separating the target variable and embeddings\n",
    "x = df[\"ada_embedding_eng\"]\n",
    "y = df['numerical_price']\n",
    "\n",
    "# Dropping the 'ada_embedding_eng' column from df\n",
    "z = df.drop([\"ada_embedding_eng\", \"numerical_price\"], axis=1)\n",
    "\n",
    "\n",
    "# Deleting original dataframe for memory purpose\n",
    "del df\n",
    "\n",
    "# Explode the embedding arrays into separate columns\n",
    "x = x.apply(pd.Series)\n",
    "\n",
    "# Concatenating the exploded embeddings with the rest of the data\n",
    "concatenated_df = pd.concat([x, z], axis=1).reset_index(drop=True)\n",
    "concatenated_df.columns = concatenated_df.columns.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(concatenated_df, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "451/451 [==============================] - 4s 7ms/step - loss: 0.3412\n",
      "Epoch 2/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2897\n",
      "Epoch 3/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2363\n",
      "Epoch 4/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.2205\n",
      "Epoch 5/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1861\n",
      "Epoch 6/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1628\n",
      "Epoch 7/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1521\n",
      "Epoch 8/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1651\n",
      "Epoch 9/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1331\n",
      "Epoch 10/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1419\n",
      "Epoch 11/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1280\n",
      "Epoch 12/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1164\n",
      "Epoch 13/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1084\n",
      "Epoch 14/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1120\n",
      "Epoch 15/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0980\n",
      "Epoch 16/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1012\n",
      "Epoch 17/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1103\n",
      "Epoch 18/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1050\n",
      "Epoch 19/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0866\n",
      "Epoch 20/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1028\n",
      "Epoch 21/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0858\n",
      "Epoch 22/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0821\n",
      "Epoch 23/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0782\n",
      "Epoch 24/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0786\n",
      "Epoch 25/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0766\n",
      "Epoch 26/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0714\n",
      "Epoch 27/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0721\n",
      "Epoch 28/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0758\n",
      "Epoch 29/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0705\n",
      "Epoch 30/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0729\n",
      "Epoch 31/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0664\n",
      "Epoch 32/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0622\n",
      "Epoch 33/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0684\n",
      "Epoch 34/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0678\n",
      "Epoch 35/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0563\n",
      "Epoch 36/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0546\n",
      "Epoch 37/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0644\n",
      "Epoch 38/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0514\n",
      "Epoch 39/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0517\n",
      "Epoch 40/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0516\n",
      "Epoch 41/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0519\n",
      "Epoch 42/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0549\n",
      "Epoch 43/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0540\n",
      "Epoch 44/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0550\n",
      "Epoch 45/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0444\n",
      "Epoch 46/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0475\n",
      "Epoch 47/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0447\n",
      "Epoch 48/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0450\n",
      "Epoch 49/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0421\n",
      "Epoch 50/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0428\n",
      "Epoch 51/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0522\n",
      "Epoch 52/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0419\n",
      "Epoch 53/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0383\n",
      "Epoch 54/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0456\n",
      "Epoch 55/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0375\n",
      "Epoch 56/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0382\n",
      "Epoch 57/92\n",
      "451/451 [==============================] - 5s 12ms/step - loss: 0.0390\n",
      "Epoch 58/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0421\n",
      "Epoch 59/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0476\n",
      "Epoch 60/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0360\n",
      "Epoch 61/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0331\n",
      "Epoch 62/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0332\n",
      "Epoch 63/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0343\n",
      "Epoch 64/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0337\n",
      "Epoch 65/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0423\n",
      "Epoch 66/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0376\n",
      "Epoch 67/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0343\n",
      "Epoch 68/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0319\n",
      "Epoch 69/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0330\n",
      "Epoch 70/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0338\n",
      "Epoch 71/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0311\n",
      "Epoch 72/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0288\n",
      "Epoch 73/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0336\n",
      "Epoch 74/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0371\n",
      "Epoch 75/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0272\n",
      "Epoch 76/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0264\n",
      "Epoch 77/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0382\n",
      "Epoch 78/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0265\n",
      "Epoch 79/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0243\n",
      "Epoch 80/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0336\n",
      "Epoch 81/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0367\n",
      "Epoch 82/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0271\n",
      "Epoch 83/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0286\n",
      "Epoch 84/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0279\n",
      "Epoch 85/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0314\n",
      "Epoch 86/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0258\n",
      "Epoch 87/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0246\n",
      "Epoch 88/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0273\n",
      "Epoch 89/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0222\n",
      "Epoch 90/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0232\n",
      "Epoch 91/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0242\n",
      "Epoch 92/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0407\n",
      "451/451 [==============================] - 1s 3ms/step\n",
      "R2 Score on Test Data: 0.8249629988961275\n",
      "Mean Squared Error: 28165245000.0\n",
      "Root Mean Squared Error: 167825.05\n",
      "Mean Absolute Error: 77036.805\n",
      "Mean Absolute percentage Error: 12.727802991867065\n",
      "explained variance 0.8249654173851013\n"
     ]
    }
   ],
   "source": [
    "r2_score_value, mse, rmse, mae, mape, explained_variance = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
    "print(\"R2 Score on Test Data:\", r2_score_value)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute percentage Error:\", mape)\n",
    "print(\"explained variance\", explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\JellevanAs\\\\Documents\\\\Studie\\\\Thesis\\\\df-dutch_cat.csv\")\n",
    "\n",
    "df.columns.tolist()\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.drop('descrip_en',axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df[\"ada_embedding\"] = df[\"ada_embedding\"].apply(literal_eval).apply(np.array)\n",
    "\n",
    "# Separating the target variable and embeddings\n",
    "x = df[\"ada_embedding\"]\n",
    "y = df['numerical_price']\n",
    "\n",
    "# Dropping the 'ada_embedding_eng' column from df\n",
    "z = df.drop([\"ada_embedding\", \"numerical_price\"], axis=1)\n",
    "\n",
    "\n",
    "# Deleting original dataframe for memory purpose\n",
    "del df\n",
    "\n",
    "# Explode the embedding arrays into separate columns\n",
    "x = x.apply(pd.Series)\n",
    "\n",
    "# Concatenating the exploded embeddings with the rest of the data\n",
    "concatenated_df = pd.concat([x, z], axis=1).reset_index(drop=True)\n",
    "concatenated_df.columns = concatenated_df.columns.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(concatenated_df, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "451/451 [==============================] - 4s 7ms/step - loss: 0.3444\n",
      "Epoch 2/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2997\n",
      "Epoch 3/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2339\n",
      "Epoch 4/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.2175\n",
      "Epoch 5/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2209\n",
      "Epoch 6/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1841\n",
      "Epoch 7/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1608\n",
      "Epoch 8/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1610\n",
      "Epoch 9/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1601\n",
      "Epoch 10/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1356\n",
      "Epoch 11/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1252\n",
      "Epoch 12/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1350\n",
      "Epoch 13/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1155\n",
      "Epoch 14/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1074\n",
      "Epoch 15/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1066\n",
      "Epoch 16/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1310\n",
      "Epoch 17/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1169\n",
      "Epoch 18/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0959\n",
      "Epoch 19/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0962\n",
      "Epoch 20/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0921\n",
      "Epoch 21/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0870\n",
      "Epoch 22/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0942\n",
      "Epoch 23/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.1065\n",
      "Epoch 24/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0861\n",
      "Epoch 25/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0770\n",
      "Epoch 26/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0783\n",
      "Epoch 27/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.0836\n",
      "Epoch 28/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0860\n",
      "Epoch 29/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0800\n",
      "Epoch 30/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0702\n",
      "Epoch 31/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0647\n",
      "Epoch 32/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0740\n",
      "Epoch 33/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0737\n",
      "Epoch 34/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0763\n",
      "Epoch 35/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0718\n",
      "Epoch 36/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0713\n",
      "Epoch 37/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0714\n",
      "Epoch 38/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0590\n",
      "Epoch 39/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0584\n",
      "Epoch 40/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0576\n",
      "Epoch 41/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0559\n",
      "Epoch 42/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0549\n",
      "Epoch 43/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0547\n",
      "Epoch 44/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0582\n",
      "Epoch 45/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0542\n",
      "Epoch 46/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0891\n",
      "Epoch 47/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0518\n",
      "Epoch 48/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0519\n",
      "Epoch 49/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0449\n",
      "Epoch 50/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0459\n",
      "Epoch 51/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0435\n",
      "Epoch 52/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0448\n",
      "Epoch 53/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0432\n",
      "Epoch 54/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0482\n",
      "Epoch 55/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0526\n",
      "Epoch 56/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0462\n",
      "Epoch 57/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0422\n",
      "Epoch 58/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0420\n",
      "Epoch 59/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0510\n",
      "Epoch 60/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0550\n",
      "Epoch 61/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0428\n",
      "Epoch 62/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0373\n",
      "Epoch 63/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0399\n",
      "Epoch 64/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0386\n",
      "Epoch 65/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0357\n",
      "Epoch 66/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0376\n",
      "Epoch 67/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0355\n",
      "Epoch 68/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0398\n",
      "Epoch 69/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0367\n",
      "Epoch 70/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0369\n",
      "Epoch 71/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0467\n",
      "Epoch 72/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0386\n",
      "Epoch 73/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0345\n",
      "Epoch 74/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0317\n",
      "Epoch 75/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0325\n",
      "Epoch 76/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0381\n",
      "Epoch 77/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0302\n",
      "Epoch 78/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0324\n",
      "Epoch 79/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0323\n",
      "Epoch 80/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0295\n",
      "Epoch 81/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0295\n",
      "Epoch 82/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0294\n",
      "Epoch 83/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0277\n",
      "Epoch 84/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0307\n",
      "Epoch 85/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0315\n",
      "Epoch 86/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0309\n",
      "Epoch 87/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0274\n",
      "Epoch 88/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0309\n",
      "Epoch 89/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0312\n",
      "Epoch 90/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0311\n",
      "Epoch 91/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0283\n",
      "Epoch 92/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0269\n",
      "451/451 [==============================] - 1s 3ms/step\n",
      "R2 Score on Test Data: 0.8365493346869841\n",
      "Mean Squared Error: 26300885000.0\n",
      "Root Mean Squared Error: 162175.47\n",
      "Mean Absolute Error: 74645.89\n",
      "Mean Absolute percentage Error: 12.45143786072731\n",
      "explained variance 0.8366832733154297\n"
     ]
    }
   ],
   "source": [
    "r2_score_value, mse, rmse, mae, mape, explained_variance = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
    "print(\"R2 Score on Test Data:\", r2_score_value)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute percentage Error:\", mape)\n",
    "print(\"explained variance\", explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numerical_price',\n",
       " 'ada_embedding_prompt',\n",
       " 'num_bedrooms',\n",
       " 'num_rooms',\n",
       " 'building_type_Bestaande bouw',\n",
       " 'building_type_Nieuwbouw',\n",
       " 'building_type_na',\n",
       " 'tag_k.k.',\n",
       " 'tag_v.o.n.',\n",
       " 'house_category_Appartement',\n",
       " 'house_category_Bungalow',\n",
       " 'house_category_Eengezinswoning',\n",
       " 'house_category_Grachtenpand',\n",
       " 'house_category_Herenhuis',\n",
       " 'house_category_Landhuis',\n",
       " 'house_category_Other',\n",
       " 'house_category_Unknown',\n",
       " 'house_category_Villa',\n",
       " 'house_category_Woonboerderij',\n",
       " 'house_category_Woonboot',\n",
       " 'energy_label_encoded',\n",
       " 'size_scaled',\n",
       " 'longitude_scaled',\n",
       " 'latitude_scaled']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\JellevanAs\\\\Documents\\\\Studie\\\\Thesis\\\\df-prompt_cat.csv\")\n",
    "\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df[\"ada_embedding_prompt\"] = df[\"ada_embedding_prompt\"].apply(literal_eval).apply(np.array)\n",
    "\n",
    "# Separating the target variable and embeddings\n",
    "x = df[\"ada_embedding_prompt\"]\n",
    "y = df['numerical_price']\n",
    "\n",
    "# Dropping the 'ada_embedding_eng' column from df\n",
    "z = df.drop([\"ada_embedding_prompt\", \"numerical_price\"], axis=1)\n",
    "\n",
    "\n",
    "# Deleting original dataframe for memory purpose\n",
    "del df\n",
    "\n",
    "# Explode the embedding arrays into separate columns\n",
    "x = x.apply(pd.Series)\n",
    "\n",
    "# Concatenating the exploded embeddings with the rest of the data\n",
    "concatenated_df = pd.concat([x, z], axis=1).reset_index(drop=True)\n",
    "concatenated_df.columns = concatenated_df.columns.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(concatenated_df, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "450/450 [==============================] - 4s 6ms/step - loss: 0.3645\n",
      "Epoch 2/92\n",
      "450/450 [==============================] - 3s 6ms/step - loss: 0.2777\n",
      "Epoch 3/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.2389\n",
      "Epoch 4/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.2385\n",
      "Epoch 5/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.2104\n",
      "Epoch 6/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1873\n",
      "Epoch 7/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.1976\n",
      "Epoch 8/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.1661\n",
      "Epoch 9/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1590\n",
      "Epoch 10/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1577\n",
      "Epoch 11/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1427\n",
      "Epoch 12/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1985\n",
      "Epoch 13/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.1431\n",
      "Epoch 14/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1208\n",
      "Epoch 15/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1166\n",
      "Epoch 16/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1092\n",
      "Epoch 17/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1070\n",
      "Epoch 18/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1235\n",
      "Epoch 19/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1229\n",
      "Epoch 20/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0939\n",
      "Epoch 21/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1155\n",
      "Epoch 22/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.1020\n",
      "Epoch 23/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0875\n",
      "Epoch 24/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0863\n",
      "Epoch 25/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0883\n",
      "Epoch 26/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0835\n",
      "Epoch 27/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0882\n",
      "Epoch 28/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0801\n",
      "Epoch 29/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0790\n",
      "Epoch 30/92\n",
      "450/450 [==============================] - 3s 7ms/step - loss: 0.0864\n",
      "Epoch 31/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0703\n",
      "Epoch 32/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0706\n",
      "Epoch 33/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0665\n",
      "Epoch 34/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0685\n",
      "Epoch 35/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0729\n",
      "Epoch 36/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0654\n",
      "Epoch 37/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0639\n",
      "Epoch 38/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0669\n",
      "Epoch 39/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0694\n",
      "Epoch 40/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0579\n",
      "Epoch 41/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0545\n",
      "Epoch 42/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0539\n",
      "Epoch 43/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0565\n",
      "Epoch 44/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0800\n",
      "Epoch 45/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0581\n",
      "Epoch 46/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0633\n",
      "Epoch 47/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0515\n",
      "Epoch 48/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0532\n",
      "Epoch 49/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0503\n",
      "Epoch 50/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0482\n",
      "Epoch 51/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0474\n",
      "Epoch 52/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0464\n",
      "Epoch 53/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0510\n",
      "Epoch 54/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0475\n",
      "Epoch 55/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0471\n",
      "Epoch 56/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0504\n",
      "Epoch 57/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0463\n",
      "Epoch 58/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0420\n",
      "Epoch 59/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0428\n",
      "Epoch 60/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0400\n",
      "Epoch 61/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0478\n",
      "Epoch 62/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0464\n",
      "Epoch 63/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0443\n",
      "Epoch 64/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0389\n",
      "Epoch 65/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0439\n",
      "Epoch 66/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0402\n",
      "Epoch 67/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0372\n",
      "Epoch 68/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0365\n",
      "Epoch 69/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0359\n",
      "Epoch 70/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0340\n",
      "Epoch 71/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0334\n",
      "Epoch 72/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0443\n",
      "Epoch 73/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0347\n",
      "Epoch 74/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0328\n",
      "Epoch 75/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0353\n",
      "Epoch 76/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0436\n",
      "Epoch 77/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0316\n",
      "Epoch 78/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0302\n",
      "Epoch 79/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0528\n",
      "Epoch 80/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0317\n",
      "Epoch 81/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0306\n",
      "Epoch 82/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0298\n",
      "Epoch 83/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0282\n",
      "Epoch 84/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0291\n",
      "Epoch 85/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0286\n",
      "Epoch 86/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0285\n",
      "Epoch 87/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0332\n",
      "Epoch 88/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0284\n",
      "Epoch 89/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0328\n",
      "Epoch 90/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0277\n",
      "Epoch 91/92\n",
      "450/450 [==============================] - 3s 8ms/step - loss: 0.0294\n",
      "Epoch 92/92\n",
      "450/450 [==============================] - 4s 8ms/step - loss: 0.0320\n",
      "450/450 [==============================] - 1s 2ms/step\n",
      "R2 Score on Test Data: 0.8595718314282405\n",
      "Mean Squared Error: 20830202000.0\n",
      "Root Mean Squared Error: 144326.72\n",
      "Mean Absolute Error: 74745.24\n",
      "Mean Absolute percentage Error: 12.666669487953186\n",
      "explained variance 0.8600616455078125\n"
     ]
    }
   ],
   "source": [
    "r2_score_value, mse, rmse, mae, mape, explained_variance = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
    "print(\"R2 Score on Test Data:\", r2_score_value)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute percentage Error:\", mape)\n",
    "print(\"explained variance\", explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\\\Users\\\\JellevanAs\\\\Documents\\\\Studie\\\\Thesis\\\\df-anti_cat.csv\")\n",
    "\n",
    "df.columns.tolist()\n",
    "\n",
    "df = df.drop(df.columns[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df[\"description_en_anti_prompt_embedding\"] = df[\"description_en_anti_prompt_embedding\"].apply(literal_eval).apply(np.array)\n",
    "\n",
    "# Separating the target variable and embeddings\n",
    "x = df[\"description_en_anti_prompt_embedding\"]\n",
    "y = df['numerical_price']\n",
    "\n",
    "# Dropping the 'ada_embedding_eng' column from df\n",
    "z = df.drop([\"description_en_anti_prompt_embedding\", \"numerical_price\"], axis=1)\n",
    "\n",
    "\n",
    "# Deleting original dataframe for memory purpose\n",
    "del df\n",
    "\n",
    "# Explode the embedding arrays into separate columns\n",
    "x = x.apply(pd.Series)\n",
    "\n",
    "# Concatenating the exploded embeddings with the rest of the data\n",
    "concatenated_df = pd.concat([x, z], axis=1).reset_index(drop=True)\n",
    "concatenated_df.columns = concatenated_df.columns.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(concatenated_df, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/92\n",
      "451/451 [==============================] - 4s 7ms/step - loss: 0.3673\n",
      "Epoch 2/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2730\n",
      "Epoch 3/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.2367\n",
      "Epoch 4/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2313\n",
      "Epoch 5/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.2013\n",
      "Epoch 6/92\n",
      "451/451 [==============================] - 3s 7ms/step - loss: 0.1819\n",
      "Epoch 7/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.2165\n",
      "Epoch 8/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.1613\n",
      "Epoch 9/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1560\n",
      "Epoch 10/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1464\n",
      "Epoch 11/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1338\n",
      "Epoch 12/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1245\n",
      "Epoch 13/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1569\n",
      "Epoch 14/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.1247\n",
      "Epoch 15/92\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1377\n",
      "Epoch 16/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1236\n",
      "Epoch 17/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1102\n",
      "Epoch 18/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1103\n",
      "Epoch 19/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1050\n",
      "Epoch 20/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1325\n",
      "Epoch 21/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0982\n",
      "Epoch 22/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0944\n",
      "Epoch 23/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0976\n",
      "Epoch 24/92\n",
      "451/451 [==============================] - 3s 8ms/step - loss: 0.0968\n",
      "Epoch 25/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0836\n",
      "Epoch 26/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0829\n",
      "Epoch 27/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0982\n",
      "Epoch 28/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0750\n",
      "Epoch 29/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0747\n",
      "Epoch 30/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0785\n",
      "Epoch 31/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0855\n",
      "Epoch 32/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0750\n",
      "Epoch 33/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0712\n",
      "Epoch 34/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0658\n",
      "Epoch 35/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0712\n",
      "Epoch 36/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0725\n",
      "Epoch 37/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0627\n",
      "Epoch 38/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0701\n",
      "Epoch 39/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0639\n",
      "Epoch 40/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0691\n",
      "Epoch 41/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0608\n",
      "Epoch 42/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0615\n",
      "Epoch 43/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0547\n",
      "Epoch 44/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0561\n",
      "Epoch 45/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0524\n",
      "Epoch 46/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0630\n",
      "Epoch 47/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0522\n",
      "Epoch 48/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0513\n",
      "Epoch 49/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0550\n",
      "Epoch 50/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0511\n",
      "Epoch 51/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0491\n",
      "Epoch 52/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0522\n",
      "Epoch 53/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0545\n",
      "Epoch 54/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0499\n",
      "Epoch 55/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0519\n",
      "Epoch 56/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0559\n",
      "Epoch 57/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0429\n",
      "Epoch 58/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0392\n",
      "Epoch 59/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0423\n",
      "Epoch 60/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0516\n",
      "Epoch 61/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0467\n",
      "Epoch 62/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0603\n",
      "Epoch 63/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0468\n",
      "Epoch 64/92\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.0380\n",
      "Epoch 65/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0374\n",
      "Epoch 66/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0465\n",
      "Epoch 67/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0484\n",
      "Epoch 68/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0402\n",
      "Epoch 69/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0349\n",
      "Epoch 70/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0358\n",
      "Epoch 71/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0367\n",
      "Epoch 72/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0541\n",
      "Epoch 73/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0359\n",
      "Epoch 74/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0364\n",
      "Epoch 75/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0374\n",
      "Epoch 76/92\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.0427\n",
      "Epoch 77/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0408\n",
      "Epoch 78/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0340\n",
      "Epoch 79/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0312\n",
      "Epoch 80/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0303\n",
      "Epoch 81/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0300\n",
      "Epoch 82/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0319\n",
      "Epoch 83/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0320\n",
      "Epoch 84/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0332\n",
      "Epoch 85/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0353\n",
      "Epoch 86/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0326\n",
      "Epoch 87/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0346\n",
      "Epoch 88/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0328\n",
      "Epoch 89/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0307\n",
      "Epoch 90/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0301\n",
      "Epoch 91/92\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.0272\n",
      "Epoch 92/92\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.0354\n",
      "451/451 [==============================] - 1s 3ms/step\n",
      "R2 Score on Test Data: 0.8376638818974989\n",
      "Mean Squared Error: 26121544000.0\n",
      "Root Mean Squared Error: 161621.61\n",
      "Mean Absolute Error: 75997.32\n",
      "Mean Absolute percentage Error: 12.512852251529694\n",
      "explained variance 0.8384499549865723\n"
     ]
    }
   ],
   "source": [
    "r2_score_value, mse, rmse, mae, mape, explained_variance = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
    "print(\"R2 Score on Test Data:\", r2_score_value)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Mean Absolute percentage Error:\", mape)\n",
    "print(\"explained variance\", explained_variance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
