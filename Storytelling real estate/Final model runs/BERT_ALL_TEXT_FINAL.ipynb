{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuxJss2f5JoK",
        "outputId": "f671d6aa-7b7a-4c24-d4a3-fc6e338eb7fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['url',\n",
              " 'price',\n",
              " 'address',\n",
              " 'descrip',\n",
              " 'listed_since',\n",
              " 'zip_code',\n",
              " 'size',\n",
              " 'year',\n",
              " 'living_area',\n",
              " 'kind_of_house',\n",
              " 'building_type',\n",
              " 'num_of_rooms',\n",
              " 'num_of_bathrooms',\n",
              " 'layout',\n",
              " 'energy_label',\n",
              " 'insulation',\n",
              " 'heating',\n",
              " 'ownership',\n",
              " 'exteriors',\n",
              " 'parking',\n",
              " 'date_list',\n",
              " 'last_ask_price',\n",
              " 'last_ask_price_m2',\n",
              " 'city',\n",
              " 'log_id',\n",
              " 'num of tokens per descrip',\n",
              " 'descrip_en',\n",
              " 'numerical_price',\n",
              " 'numerical_price_per_m2',\n",
              " 'tag',\n",
              " 'house_category',\n",
              " 'living_area_float',\n",
              " 'size_float',\n",
              " 'zip_code_4_digits',\n",
              " 'postcode',\n",
              " 'latitude',\n",
              " 'longitude',\n",
              " 'embeddings']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# This will prompt for authorization to access your Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Update the file path to the location where you uploaded your CSV in Google Drive\n",
        "file_path = '/content/drive/My Drive/Thesis/df-BERT.csv'\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "\n",
        "# Display the column names\n",
        "df.columns.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your original DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from ast import literal_eval\n",
        "\n",
        "\n",
        "# Convert the 'ada_embedding_eng' column to a list of arrays if they are not already\n",
        "df[\"embeddings\"] = df[\"embeddings\"].apply(literal_eval).apply(np.array)\n",
        "\n",
        "x = df[\"embeddings\"]\n",
        "y = df['numerical_price']\n",
        "\n",
        "\n",
        "###### deleting original dataframe for memory purpose ####\n",
        "del df"
      ],
      "metadata": {
        "id": "ggmMXlSq5i3K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x = x.apply(pd.Series)\n",
        "\n",
        "# First split: separate out a test set\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "nUu5B9Eb5oVV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate(x_train, y_train, x_test, y_test, best_params):\n",
        "    \"\"\"\n",
        "    Trains the Random Forest model with the given parameters and evaluates it on the test set.\n",
        "\n",
        "    Parameters:\n",
        "    x_train (list/array): Training features\n",
        "    y_train (list/array): Training target variable\n",
        "    x_test (list/array): Test features\n",
        "    y_test (list/array): Test target variable\n",
        "    best_params (dict): Dictionary of best hyperparameters\n",
        "\n",
        "    Returns:\n",
        "    dict: Dictionary containing R2, MSE, and RMSE metrics\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize RandomForestRegressor with best parameters\n",
        "    clf_rf_best = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "\n",
        "    # Initialize and fit StandardScaler on y_train\n",
        "    scaler = StandardScaler()\n",
        "    y_train_scaled = scaler.fit_transform(np.array(y_train).reshape(-1, 1))\n",
        "\n",
        "    # Train the model on the entire training dataset\n",
        "    clf_rf_best.fit(x_train, y_train_scaled.ravel())\n",
        "\n",
        "    # Predict on the test data and inverse transform the predictions\n",
        "    y_pred_scaled = clf_rf_best.predict(x_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "      # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R-squared Score\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    # Explained Variance Score\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    return {\"R2\": r2_score_value, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape,\"explained\":explained_variance}\n",
        "\n",
        "# Best parameters from cross-validation\n",
        "best_params = {'max_depth': 16, 'n_estimators': 900, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'bootstrap': False}\n",
        "\n",
        "\n",
        "\n",
        "performance_metrics = train_and_evaluate(x_train, y_train, x_test, y_test, best_params)\n",
        "print(\"Final Model Performance on Test Set:\", performance_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBvd58uW52Ga",
        "outputId": "8a0c52fb-db78-4a8a-8838-31f9f6b13eab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model Performance on Test Set: {'R2': 0.3154412647152307, 'MSE': 109373871490.57896, 'RMSE': 330717.2077327985, 'MAE': 176699.8630821869, 'MAPE': 36.94779288046121, 'explained': 0.31557838896551216}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def run_svr_and_evaluate(x_train,x_test, y_train,y_test, ):\n",
        "    # Split data into training and testing sets\n",
        "\n",
        "\n",
        "    # Initialize SVR with your predefined parameters\n",
        "    clf_svr_opt = clf_linear_svr = LinearSVR(**linear_svr_params, random_state=0)\n",
        "\n",
        "    # StandardScaler for y\n",
        "    scaler = StandardScaler()\n",
        "\n",
        "    # Scaling\n",
        "    y_train_scaled = scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "\n",
        "    # Fitting the model\n",
        "    clf_svr_opt.fit(x_train, y_train_scaled)\n",
        "\n",
        "    # Predicting and inverse transformation for the test set\n",
        "    y_pred_scaled = clf_svr_opt.predict(x_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "      # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R-squared Score\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    # Explained Variance Score\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    return {\"R2\": r2_score_value, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape,\"explained\":explained_variance}\n",
        "\n",
        "\n",
        "\n",
        "linear_svr_params = {'C': 0.32229360417490505, 'epsilon': 0.04136883229487408, 'tol': 0.00041905031546814767, 'loss': 'squared_epsilon_insensitive', 'dual': True, 'fit_intercept': False, 'intercept_scaling': 2.8419375853277256, 'max_iter': 4824}\n",
        "\n",
        "performance_metrics = run_svr_and_evaluate(x_train=x_train,x_test=x_test, y_train=y_train,y_test=y_test)\n",
        "print(performance_metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_936GwO-7Far",
        "outputId": "b683afcb-89ea-456a-dc68-51648082cff3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'R2': 0.3722086382746581, 'MSE': 100303988804.8169, 'RMSE': 316708.0497947864, 'MAE': 186467.44341936865, 'MAPE': 37.957581710712766, 'explained': 0.3723538455587867}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "\n",
        "\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "\n",
        "y_train = np.ravel(y_train)\n",
        "y_test = np.ravel(y_test)\n",
        "\n",
        "\n",
        "print(\"Adjusted y_train shape:\", y_train.shape)\n",
        "print(\"Adjusted y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjMGR0tR6aNe",
        "outputId": "2d5f7a1e-e4a5-450a-9df8-0198cbfb12ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (57611, 768)\n",
            "x_test shape: (14403, 768)\n",
            "y_train shape: (57611,)\n",
            "y_test shape: (14403,)\n",
            "Adjusted y_train shape: (57611,)\n",
            "Adjusted y_test shape: (14403,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
        "import numpy as np\n",
        "\n",
        "def train_and_evaluate_model(x_train, y_train, x_test, y_test, params):\n",
        "    \"\"\"\n",
        "    Train and evaluate a neural network model.\n",
        "\n",
        "    Parameters:\n",
        "    - x_train: Training features\n",
        "    - y_train: Training target values\n",
        "    - x_test: Test features\n",
        "    - y_test: Test target values\n",
        "    - params: Dictionary containing the optimal parameters\n",
        "\n",
        "    Returns:\n",
        "    - R2 score, MSE, and RMSE on the test set.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    model = Sequential()\n",
        "    if params['regularization'] == 'l1':\n",
        "        reg = l1(params['l1_reg'])\n",
        "    elif params['regularization'] == 'l2':\n",
        "        reg = l2(0)\n",
        "    elif params['regularization'] == 'l1_l2':\n",
        "        reg = l1_l2(l1=params['l1_reg'], l2=0)\n",
        "    else:\n",
        "        reg = None\n",
        "\n",
        "    model.add(Dense(params['neurons_layer_1'], activation='relu', input_shape=(x_train.shape[1],), kernel_regularizer=reg))\n",
        "    model.add(Dense(params['neurons_layer_2'], activation='relu', kernel_regularizer=reg))\n",
        "    model.add(Dense(params['neurons_layer_3'], activation='relu', kernel_regularizer=reg))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=params['learning_rate'])\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    # Scaling y_train\n",
        "    scaler = StandardScaler()\n",
        "    y_train_scaled = scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Fit the model\n",
        "    model.fit(x_train, y_train_scaled, epochs=params['epochs'], batch_size=params['batch_size'], verbose=1)\n",
        "\n",
        "    # Predict and evaluate on the test set\n",
        "    y_pred_scaled = model.predict(x_test)\n",
        "    y_pred = scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "      # Mean Squared Error\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    # Root Mean Squared Error\n",
        "    rmse = np.sqrt(mse)\n",
        "    # R-squared Score\n",
        "    r2_score_value = r2_score(y_test, y_pred)\n",
        "    # Mean Absolute Error\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    # Mean Absolute Percentage Error\n",
        "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "    # Explained Variance Score\n",
        "    explained_variance = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    return {\"R2\": r2_score_value, \"MSE\": mse, \"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape,\"explained\":explained_variance}\n",
        "\n",
        "\n",
        "optimal_params = {'learning_rate': 0.00013189685881053736, 'neurons_layer_1': 240, 'neurons_layer_2': 384, 'neurons_layer_3': 48, 'batch_size': 128, 'epochs': 57, 'regularization': 'none'}\n",
        "\n",
        "\n",
        "\n",
        "performance_metrics = train_and_evaluate_model(x_train, y_train, x_test, y_test, optimal_params)\n",
        "print(\"Final Model Performance on Test Set:\", performance_metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIoLDPbG6nob",
        "outputId": "aa00d700-293c-470d-da3f-040bf10229e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/57\n",
            "451/451 [==============================] - 4s 6ms/step - loss: 0.8670\n",
            "Epoch 2/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.7445\n",
            "Epoch 3/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.7106\n",
            "Epoch 4/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.6781\n",
            "Epoch 5/57\n",
            "451/451 [==============================] - 3s 7ms/step - loss: 0.6610\n",
            "Epoch 6/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.6479\n",
            "Epoch 7/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.6336\n",
            "Epoch 8/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.6390\n",
            "Epoch 9/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.6188\n",
            "Epoch 10/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.6147\n",
            "Epoch 11/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.6105\n",
            "Epoch 12/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.6105\n",
            "Epoch 13/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5964\n",
            "Epoch 14/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5854\n",
            "Epoch 15/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5923\n",
            "Epoch 16/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5869\n",
            "Epoch 17/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5835\n",
            "Epoch 18/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5652\n",
            "Epoch 19/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5676\n",
            "Epoch 20/57\n",
            "451/451 [==============================] - 2s 6ms/step - loss: 0.5753\n",
            "Epoch 21/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5603\n",
            "Epoch 22/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5674\n",
            "Epoch 23/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5709\n",
            "Epoch 24/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5620\n",
            "Epoch 25/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5333\n",
            "Epoch 26/57\n",
            "451/451 [==============================] - 3s 7ms/step - loss: 0.5432\n",
            "Epoch 27/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5374\n",
            "Epoch 28/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5951\n",
            "Epoch 29/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5485\n",
            "Epoch 30/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5440\n",
            "Epoch 31/57\n",
            "451/451 [==============================] - 3s 7ms/step - loss: 0.5415\n",
            "Epoch 32/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5513\n",
            "Epoch 33/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5370\n",
            "Epoch 34/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5154\n",
            "Epoch 35/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5227\n",
            "Epoch 36/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5319\n",
            "Epoch 37/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5063\n",
            "Epoch 38/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5143\n",
            "Epoch 39/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5397\n",
            "Epoch 40/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5408\n",
            "Epoch 41/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5127\n",
            "Epoch 42/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5138\n",
            "Epoch 43/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5226\n",
            "Epoch 44/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4922\n",
            "Epoch 45/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5109\n",
            "Epoch 46/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.4876\n",
            "Epoch 47/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.5261\n",
            "Epoch 48/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4915\n",
            "Epoch 49/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4792\n",
            "Epoch 50/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4828\n",
            "Epoch 51/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.4692\n",
            "Epoch 52/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.4614\n",
            "Epoch 53/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4938\n",
            "Epoch 54/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.4683\n",
            "Epoch 55/57\n",
            "451/451 [==============================] - 2s 5ms/step - loss: 0.5082\n",
            "Epoch 56/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.4536\n",
            "Epoch 57/57\n",
            "451/451 [==============================] - 3s 6ms/step - loss: 0.4717\n",
            "451/451 [==============================] - 1s 1ms/step\n",
            "Final Model Performance on Test Set: {'R2': 0.46847468882226373, 'MSE': 84923291577.8369, 'RMSE': 291416.01118990855, 'MAE': 162853.65418771264, 'MAPE': 30.432387157378926, 'explained': 0.46972876688157195}\n"
          ]
        }
      ]
    }
  ]
}